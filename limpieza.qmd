---
title: "Procesamiento y limpieza de texto con stringr, regex y la inteligencia artificial"
author:
  - name: "Ismael Aguayo"
    orcid: "0009-0002-4056-8242"
date: today
lang: es
fontsize: 14pt
format:
  html:
    code-fold: false
    toc: true
    toc-location: left
    toc-depth: 2
    toc-expand: 1
    toc-title: Contents
    number-sections: true
    number-depth: 2
    theme: socialtec.scss
    code-link: true
    title-block-banner: true
editor_options: 
  chunk_output_type: console
---

# Configuraci칩n de la sesi칩n e introducci칩n

Hola a tod@s. Bienvenidos a este tutorial sobre procesamiento y limpieza de texto en R, en el marco del curso de M칠todos Computacionales para las Ciencias Sociales de la FACSO. Si est치n viendo esto fuera de la asignatura, espero que les sirva de igual manera.

En la unidad anterior, aprendieron a extraer datos, ya sea desde APIs o usando t칠cnicas de web scraping. Lo m치s probable es que esos datos, tal como los tienen ahora, no est칠n listos para ser analizados. Seguramente tienen caracteres extra침os, etiquetas HTML, saltos de l칤nea, o simplemente un formato desordenado.

El objetivo de esta sesi칩n es aprender los fundamentos para limpiar ese "texto sucio" y dejarlo preparado para un an치lisis de NLP.

Vamos a empezar configurando nuestra sesi칩n de R.

## Carga de librer칤as

```{r}
#install_packages(pacman)
library(pacman)
pacman::p_load(stringr)
```

La librer칤a clave de hoy es stringr. stringr es parte del tidyverse y es nuestra herramienta clave para manipular texto. Nos da un conjunto de funciones muy consistentes y f치ciles de entender para todas las operaciones comunes con strings/characters, y funciona de forma vectorial.

## Creamos datos simulados de texto sucio en un dataframe

Para esta c치psula, no vamos a cargar un set de datos gigante. Como cada uno de ustedes tiene datos distintos, con problemas de limpieza diferentes, lo m치s 칰til es crear nuestros propios datos simulados.

Vamos a crear un data.frame que contenga distintos tipos de "suciedad" que probablemente ustedes mismos est치n viendo en sus propios datos.

```{r}
df_sucios <- data.frame(
  id = 1:4,
  texto = c(
    "<p>Este es el primer texto. Con etiquetas de html.</p>",
    "    HOLA MUNDO, este es el segundo texto. Con espacios extra.    ",
    "<div>Aqu칤 hay <strong>m치s</strong> suciedad!\nY un salto de l칤nea.</div>",
    "Un texto final @usuario con un link http://socialtec.cl y #hashtag"
  )
)

print(df_sucios)
```

- En la fila 1, tenemos etiquetas HTML `<p>`

- En la fila 2, tenemos may칰sculas descontroladas y un mont칩n de espacios en blanco in칰tiles al principio y al final.

- En la fila 3, tenemos m치s HTML, incluso anidado (`<strong>`), y un salto de l칤nea \n.

- Y en la fila 4, tenemos ruido t칤pico de redes sociales: una menci칩n, un link (URL) y un hashtag.

# Introducci칩n a las funciones de stringr

Ahora que tenemos nuestros datos sucios en un dataframe, vamos a explorar las funciones clave de stringr para limpiarlos.

Iremos una por una, viendo qu칠 hacen y c칩mo nos ayudan a resolver los problemas que identificamos. Para estos ejemplos, vamos a trabajar con los textos individuales de nuestro dataframe. M치s adelante veremos c칩mo automatizar esto para todo el dataframe.

Empecemos por el Texto 2, que ten칤a dos problemas obvios: may칰sculas y espacios en blanco.

```{r}
texto_2 <- df_sucios$texto[2]
print(texto_2)
```

Para el an치lisis de texto, la m치quina considera "hola" y "HOLA" como cosas distintas. Debemos normalizar este texto.

## str_to_lower

```{r}
texto_minusculas <- str_to_lower(texto_2)
print(texto_minusculas)
```

Ahora todo est치 en min칰sculas, pero seguimos teniendo espacios en blanco al inicio y al final. Esto puede obstaculizar nuestro conteo de palabras y an치lisis.

## str_trim

Para eso, usamos str_trim, que "recorta" el espacio en blanco de ambos extremos.

```{r}
texto_limpio_2 <- str_trim(texto_minusculas)
print(texto_limpio_2)
```

Ya tenemos un texto mucho m치s limpio. Podr칤amos hacer todo esto en un solo paso:

```{r}
str_trim(str_to_lower(texto_2))
```

## str_sub

A veces queremos extraer texto bas치ndonos en su posici칩n. Por ejemplo, los primeros 10 caracteres. Para eso usamos str_sub.

```{r}
texto_1 <- df_sucios$texto[1]
print(texto_1)
```

```{r}
str_sub(texto_1, start = 1, end = 10)
```

Rara vez sabemos el lugar o 칤ndice exacto de la suciedad, pero igual es 칰til que sepan de la existencia de esta funci칩n.

## Diagnosticando: str_length y str_detect

Antes de limpiar, generalmente necesitamos diagnosticar el corpus de texto que tenemos. En muchos casos es imposible hacer esto manualmente, ya que consta de muchas filas (miles o cientos de miles). Para esto utilizamos `str_length` y `str_detect`.

```{r}
str_length(texto_1)
str_length(texto_limpio_2)
```

`str_length` nos indica el n칰mero de caracteres de un texto. Nos puede servir para filtrar textos vac칤os.

Aqu칤 nuestro mayor aliado es `str_detect`, que nos devuelve TRUE o FALSE si encuentra un patr칩n.

En el texto 4, 쯛ay un link a una p치gina web? Busquemos si contiene "http".

```{r}
texto_4 <- df_sucios$texto[4]
print(texto_4)
```

```{r}
str_detect(texto_4, pattern = "http")
```

Esta funci칩n es muy 칰til para hacer filtros y categor칤as. Podr칤amos por ejemplo crear una nueva columna que nos indique qu칠 textos contienen un hashtag.

```{r}
str_detect(texto_4, pattern = "#")
```

## Reemplazando la suciedad: str_replace (o str_remove)

Podemos reemplazar un determinado patr칩n con la funci칩n `str_replace`. Si reemplazamos por nada, estar칤amos simulando el comportamiento de la funci칩n `str_remove`.

```{r}
print(texto_1)
texto_sin_p <- str_replace(texto_1, pattern = "<p>", replacement = "") 
print(texto_sin_p)

```

Tendr칤amos que hacer dos pasos, uno para cada etiqueta HTML.

```{r}
texto_sin_p <- str_replace(texto_sin_p, pattern = "</p>", replacement = "") 
print(texto_sin_p)
```

Si quisi칠ramos eliminar todas las coincidencias de un patr칩n usamos `str_replace_all`, pero en este caso tendr칤amos el mismo problema. Esto ya que busca un patr칩n exacto. Si queremos eliminar todas las etiquetas HTML vamos a necesitar usar expresiones regulares.

```{r}
print(texto_1)
texto_sin_p <- str_replace_all(texto_1, pattern = "<p>", replacement = "") 
print(texto_sin_p)

texto_sin_letra_e <- str_replace_all(texto_1, pattern = "e", replacement = "") 

print(texto_sin_letra_e)

```

Para eliminar todas las letras "e" s칤 funciona.

## str_extract

Si quisi칠ramos extraer solo una parte del corpus, por ejemplo el hashtag, nos sirve esta funci칩n. Aqu칤 viene un adelanto de expresiones regulares. Le estamos pidiendo un \# seguido de una cantidad de letras o n칰meros.

```{r}
print(texto_4)
str_extract(texto_4, pattern = "#[A-Za-z0-9]+")
```

Solo extraer치 la primera coincidencia, si queremos todas se utiliza `str_extract_all`.

## str_split

Str_split nos permite "romper" un texto en pedazos, usando un separador que elijamos. Esto es la base de la tokenizaci칩n (separar un texto en palabras), algo que ver치n m치s en los pr칩ximos contenidos del curso.

Usemos el texto 2 limpio que ya procesamos y separ칠moslo por los espacios.

```{r}
print(texto_limpio_2)

lista <- str_split(texto_limpio_2, pattern = " ", simplify= F)
matriz <- str_split(texto_limpio_2, pattern = " ", simplify= T)
vector <- unlist(lista)
```

Como ven, tenemos diferentes opciones de outputs.

# Expresiones regulares para casos m치s complejos

```{r}
texto_1 <- df_sucios$texto[1]
texto_3 <- df_sucios$texto[3]
print(texto_1)
print(texto_3)
```

Ya sabemos que `str_replace_all(texto_1, pattern = "<p>", replacement = "")` no es suficiente, ya que tenemos `</p>`, y en el texto 3 tenemos divs, strongs y incluso un salto de l칤nea. No podemos escribir c칩digo distinto para cada caso espec칤fico que encontremos en nuestros corpus.

Lo que necesitamos es una forma de decirle a R: "No busques el texto literal `<p>`. Busca un patr칩n que se vea como una etiqueta HTML".

Para esto utilizamos las expresiones regulares.

Aqu칤 hay un 칤ndice de algunos metacaracteres y qu칠 significan:

![](Regex-Cheat-Sheet-3362983929.png)

Lo importante no es que se los memoricen, sino que entiendan su funcionamiento general. El poder de regex nos permite en el par치metro 'pattern' especificar un rango de opciones mucho mayor que les ayudar치 a limpiar sus textos de forma mucho m치s eficaz.

- . significa cualquier car치cter
- + significa uno o m치s del car치cter anterior

Intentemos eliminar todo lo que est칠 entre un '<' y otro '>'.
```{r}

str_remove_all(texto_1, pattern = "<.+>")
```

Elimina todo. 쯇or qu칠 pasa esto? El cuantificador + es "codicioso", intentar치 borrar todo lo posible, encuentra el primer <, empieza a eliminar, y no se detuvo hasta encontrar el 칰ltimo >.

Una forma de solucionarlo es utilizando el cuantificador perezoso, le decimos que se detenga en la primera coincidencia posible.

```{r}

str_remove_all(texto_1, pattern = "<.+?>")
```

Esto funciona, pero hay una forma m치s robusta de resolverlo. Podemos pedirle espec칤ficamente que no elimine ning칰n ">". 

Para "cualquier car치cter que NO sea...", usamos la clase negada: [^...]. Esto es m치s seguro y preferible. Probamos con el texto 3 y vemos que funciona, eliminando todas las etiquetas HTML.

```{r}
texto_1_limpio <- str_remove_all(texto_1, pattern = "<[^>]+>")

texto_1_limpio

print(texto_3)

texto_3_casi_limpio <- str_remove_all(texto_3, pattern = "<[^>]+>")

print(texto_3_casi_limpio)
```

Como ven, el texto 3 ya est치 casi listo para analizarlo, pero queda un salto de l칤nea. Podemos reemplazarlo con replace_all (o remove_all) por un espacio o por nada. Miren sus datos para saber esto, normalmente los saltos de l칤nea (\n) deber치n cambiarlos por un espacio.
```{r}
texto_3_limpio <- str_replace_all(texto_3_casi_limpio, pattern="\n", " ")

print(texto_3_limpio)
```

# Automatizando la limpieza en corpus grandes de texto

Ya vimos c칩mo limpiar un texto con stringr y regex, en diferentes situaciones, pero 쮺칩mo lo hacemos en un dataframe completo? Tenemos varios enfoques.

Primero, simularemos un dataframe de 100 filas con datos sucios. 
```{r}
set.seed(123) # Para que los resultados sean reproducibles
titulos <- c("<p>GRAN NOTICIA</p>", "<div>impacto</div>", "<strong>칔LTIMO MINUTO</strong>")
contenidos <- c(
  "Un texto de ejemplo con <b>mucha</b> suciedad html.",
  "OTRO TEXTO que necesita limpieza urgente.",
  "    muchos espacios al inicio y final    "
)
df_grande <- data.frame( id_noticia = 1:100, titulo = sample(titulos, 100, replace = TRUE), contenido = sample(contenidos, 100, replace = TRUE) )

print(head(df_grande))
```

Tenemos HTML, may칰sculas y espacios por todos lados. Necesitamos aplicar una limpieza en varios pasos:

1. Remover todo el HTML (`<[^>]+>`)
2. Convertir todo a min칰sculas (`str_to_lower`)
3. Quitar espacios al inicio y final (`str_trim`)

## Funci칩n de limpieza

Primero, creamos una funci칩n que aplique estos tres pasos de forma unificada. Esto hace el c칩digo legible, reutilizable y f치cil de mejorar.

```{r}
limpiar_mi_texto <- function(texto_sucio) {
  
  # Paso 1: Remover HTML
  texto_limpio <- str_remove_all(texto_sucio, pattern = "<[^>]+>")
  
  # Paso 2: Convertir a min칰sculas
  texto_limpio <- str_to_lower(texto_limpio)
  
  # Paso 3: Quitar espacios extra
  texto_limpio <- str_trim(texto_limpio)
  
  # Devolvemos el texto limpio
  return(texto_limpio)
}
```

Probamos la funci칩n:

```{r}
print(df_grande$contenido[1])
limpiar_mi_texto(df_grande$contenido[1])
print(df_grande$titulo[1])
limpiar_mi_texto(df_grande$titulo[1])

```

Funciona! Ahora solo hay que aplicarla a cada fila.

## Primer enfoque: for loop

Esta es la pr치ctica m치s transparente y legible. Iteramos por cada fila, aplicamos la funci칩n y guardamos el contenido en un vector de caracteres. Luego, asignamos ese vector a una nueva columna (contenido limpio for).
```{r}
resultados_limpios_for <- c()

for (i in 1:nrow(df_grande)) {
  texto_a_limpiar <- df_grande$contenido[i]
  texto_ya_limpio <- limpiar_mi_texto(texto_a_limpiar)
  resultados_limpios_for[i] <- texto_ya_limpio 
}

df_grande$contenido_limpio_for <- resultados_limpios_for

print(head(df_grande$contenido_limpio_for))

```


## Segundo enfoque: La familia `apply`

En sus entregas, muchos utilizaron este enfoque (con `sapply` o `lapply`). Es la forma m치s compacta de realizar esto, pero es esencial que comprendan lo que est치 ocurriendo por detr치s. 

```{r}
resultados_limpios_sapply <- sapply(df_grande$contenido, limpiar_mi_texto)

df_grande$contenido_limpio_sapply <- resultados_limpios_sapply

print(head(df_grande$contenido_limpio_sapply))

```

Como ven, ambos enfoques dan el mismo resultado. Sapply por detr치s es un bucle for, que itera por cada elemento y devuelve un vector. Lo m치s importante es la funci칩n que ustedes construyen y le entregan a sapply, en este caso, `limpiar_mi_texto`.

## Tercer enfoque: m칠todo directo

`stringr`, al igual que muchos paquetes del tidyverse funciona de forma vectorial. Para casos m치s sencillos es posible que simplemente aplicando las funciones de stringr sobre la columna ya lleguen a solucionar su problema. Este enfoque es mucho m치s eficiente, asi que prefi칠ranlo si est치n trabajando con grandes vol칰menes de datos. En vez de iterar de a una fila a la vez, se aplica la funci칩n sobre toda la columna (como un vector) de manera simult치nea, utilizando un lenguaje mucho m치s eficiente por detr치s (c++).

```{r}
df_grande$contenido_limpio_vec <- limpiar_mi_texto(df_grande$contenido)

print(head(df_grande$contenido_limpio_vec))

```

Todos estos enfoques nos sirven para t칤tulos:

```{r}
df_grande$titulo_limpio<- limpiar_mi_texto(df_grande$titulo)

```

# Uso de Inteligencia Artificial Generativa: Pr치cticas generales

Llegando al final de este taller, es crucial abordar el tema del uso de Inteligencia Artificial. Esta ha sido muy utilizada en sus entregas, e incluso es un objetivo pedag칩gico que aprendan a usarla. La IA es una herramienta muy poderosa para programar.

Sin embargo, para usarla de forma eficaz hay que seguir buenas pr치cticas, y no basta con copiar y pegar lo que les pasa el chatbot. De esta forma, se quedan en la "caja negra", obtienen el resultado, pero no aprenden, y si su c칩digo falla en un futuro no sabr치n c칩mo arreglarlo.

El objetivo de este m칩dulo es prepararlos para usar la IA como un co-piloto, que les ayude a acelerar el trabajo pero tambi칠n a aprender.

## T칠cnicas de prompteo: c칩mo pedir bien

La respuesta de la IA depende totalmente de la calidad de su pregunta. Este es un marco que yo utilizo para sacar el mayor provecho de estas herramientas y que me entreguen c칩digo de mayor calidad posible, en cuatro pasos:

1. **Rol:** "Toma el rol de un experto en Procesamiento de Lenguaje Natural y programador senior de R, especializado en el Tidyverse".
2. **Tarea:** "Necesito procesar un dataframe en R".
3. **Contexto:** (춰La parte m치s importante!) "Tengo un dataframe con n filas y estas columnas: id_noticia y contenido. La columna contenido tiene texto sucio. Un ejemplo de una celda de contenido es: 'Un texto final @usuario con un link http://socialtec.cl y #hashtag'"
4. **Reglas y formato:** "Necesito una funci칩n de R que tome este texto y:

- Elimine todas las URLs que empiecen con 'http'.

- Elimine todas las menciones (ej. '@usuario').

- Extraiga (no elimine) los hashtags y los ponga en una nueva columna.

- Por favor, explica cada paso de la funci칩n con comentarios en el c칩digo.

- Prioriza usar bucles for en lugar de sapply para que yo pueda entender la l칩gica de la iteraci칩n."

De esta forma, no solo obtendr치n un c칩digo que funciona, sino tambi칠n entender치n por qu칠 resulta, asegur치ndose una explicaci칩n detallada de cada paso l칩gico. 

## Pr치cticas generales para usar la IA como co-piloto

1.  Pedirle que les expliquen lo que est치 haciendo, si no entienden cada uno de los pasos algo est치 mal. D칤ganle que les explique el c칩digo paso a paso y de forma sencilla.
2.  Intentar que no comprima tanto el c칩digo. Las funciones de la familia apply son 칰tlies para c칩digo de producci칩n y para usuarios de R avanzados, pero disminuyen la legibilidad y no permiten ver la l칩gica detr치s de las funciones que construyen. Necesitan c칩digo legible y comprensible, y una cadena de muchos `df$limpio <- sapply(df$sucio, function(x) str_trim(str_to_lower(x)))` puede ser muy compleja.
3. 칔senla como depurador (Debugger): 춰Es de los mejores usos! intenten avanzar lo que m치s puedan por su cuenta, y utilicen la Inteligencia Artificial para diagnosticar y resolver los errores que encuentren en el c칩digo.
4. La IA inventa y alucina. Siempre revisen la documentaci칩n oficial de los paquetes como referencia, sobre todo para los procedimientos m치s sensibles (por ejemplo, si van a ejecutar algo en una base de datos y no tienen un backup, no peguen un c칩digo de la IA sin pensarlo).
5. **Muy importante:** Si manejan datos sensibles tengan mucho cuidado con las pol칤ticas de la IA que est치n utilizando. No manden nunca datos privados que luego puedan utilizar para entrenar a sus modelos. 

# Cierre y ejercicios

Con esto llegamos al final de la c치psula. Hasta ahora:

1. Revisamos las funciones de `stringr` en casos de uso aplicados
2. Entendimos para qu칠 necesitamos `regex` y lo utilizamos para limpiar etiquetas de HTML
3. Aprendimos a automatizar la limpieza de texto en dataframes, creando una funci칩n y aplic치ndola a trav칠s de tres enfoques: `for loop`, `sapply` y vectorizaci칩n
4. Vimos como usar la IA como co-piloto en nuestro aprendizaje

La idea es que este taller les sirva para limpiar texto independiente del contexto en el que lo necesiten realizar. El proceso de limpieza no es lineal, es iterativo. Probablemente intentar치n una funci칩n, luego ver치n otro car치cter indeseado, corregir치n su funci칩n y seguir치n iterando.

Para practicar esto, les dejo los dos siguientes ejercicios:

## HTML anidado

Este es un solo texto. El desaf칤o es que tiene varias etiquetas HTML anidadas y un salto de l칤nea.
```{r}
texto_ej_1 <- "<div><p>Un <b>art칤culo</b> nuevo! \n (Leer m치s en...)</p></div>"
```

TAREA: Escribe el c칩digo para limpiar 'texto_ej_1'. El resultado final deber칤a ser un solo string: "Un art칤culo nuevo! (Leer m치s en...)"

Necesitar치n al menos dos pasos:
1. Remover todo el HTML
2. Reemplazar el salto de l칤nea 

## Dataframe de tweets

Aqu칤 hay un data.frame de tweets
```{r}
# Datos para el ejercicio 2
df_tweets <- data.frame(
  id_tweet = c(101, 102, 103),
  texto_tweet = c(
    "춰Qu칠 buen an치lisis de @autor_famoso! Revisa su paper en http://link.cl/paper1 #CienciaSocial",
    "No estoy de acuerdo con el 2do punto... \n\n #debate 游녩",
    "    termin칠 de leer el texto para ma침ana    "
  )
)
```

TAREA: Crea una NUEVA funci칩n llamada limpiar_tweet(texto).

Tu funci칩n debe hacer (al menos) los siguientes pasos: a. Remover todas las URLs (Pista: un patr칩n simple es http\\S+, que significa 'http' seguido de uno o m치s caracteres que no sean espacios). b. Remover todas las menciones (Pista: @ seguido de caracteres). c. Remover todos los hashtags. d. Reemplazar los saltos de l칤nea \n por un espacio " ". e. Poner todo en min칰sculas. f. Quitar los espacios de los costados (str_trim).

Aplica tu nueva funci칩n limpiar_tweet al dataframe df_tweets (usando for, sapply o el m칠todo vectorial directo).

Guarda el resultado en una nueva columna llamada texto_limpio.

Bonus: Crea una nueva columna con los hashtags.